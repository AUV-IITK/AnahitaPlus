<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.18"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Anahita: vision_tasks</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Anahita
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.18 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">vision_tasks </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md138"></a>
Overview</h1>
<p>This is a ROS package for processing video feed provided by <a href="https://github.com/AUV-IITK/Hyperion-Software/tree/master/hardware_layer/hardware_camera"><code>hardware_camera</code></a> and publishing the coordinates of the object of interest in the camera's frame as a <a href="http://docs.ros.org/kinetic/api/geometry_msgs/html/msg/PointStamped.html">geometry_msgs/PointStamped</a> or <a href="http://docs.ros.org/api/geometry_msgs/html/msg/Pose2D.html">geometry_msgs/Pose2D</a> to the other layers.</p>
<p>The <code>vision_tasks</code> package has been tested under <a href="http://www.ros.org">ROS</a> Kinetic and Ubuntu 16.04 LTS. The source code is released under a <a href="../../LICENSE">BSD 3-Clause license</a>.</p>
<p>The hardware used are as follows:</p><ul>
<li>Front-facing Camera: <a href="https://www.logitech.com/en-in/product/c930e-webcam">Logitech C930e</a></li>
<li>Bottom-facing Camera: <a href="https://www.logitech.com/en-in/product/c930e-webcam">Logitech C930e</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md139"></a>
Setting up vision_tasks</h1>
<h2><a class="anchor" id="autotoc_md140"></a>
Dependencies</h2>
<ul>
<li><a href="http://wiki.ros.org">Robot Operating System (ROS)</a> (middleware for robotics),</li>
<li>Following ROS Packages: <a href="http://wiki.ros.org/cv_bridge">cv_bridge</a> <a href="http://wiki.ros.org/sensor_msgs">sensor_msgs</a> <a href="http://wiki.ros.org/std_msgs">std_msgs</a> <a href="http://wiki.ros.org/dynamic_reconfigure">dynamic_reconfigure</a> <a href="http://wiki.ros.org/image_transport">image_transport</a></li>
</ul>
<h2><a class="anchor" id="autotoc_md141"></a>
Building</h2>
<p>Run the following command: </p><div class="fragment"><div class="line">cd ~/catkin_ws</div>
<div class="line">catkin_make --pkg vision_tasks</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md142"></a>
Usage</h1>
<p>To run any vision task named <code>&lt;name&gt;</code>, run: </p><div class="fragment"><div class="line">rosrun vision_tasks &lt;name&gt;</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md143"></a>
Nodes</h1>
<h2><a class="anchor" id="autotoc_md144"></a>
buoy_task</h2>
<p>This task pre-processes (blue-filters) the raw image, applies thresholding on the image, draws a minimum enclosing circle on the main blob and returns the coordinates of the buoy in the camera's reference frame. The distance of the buoy from the camera is calculated using an exponential mapping of the radius of the minimum enclosing circle and the actual distance.</p>
<h3><a class="anchor" id="autotoc_md145"></a>
Published Topics</h3>
<ul>
<li>**<code>/buoy_task/blue_filtered</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/buoy_task/thresholded</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/buoy_task/marked</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/buoy_task/buoy_coordinates</code>** (<a href="http://docs.ros.org/kinetic/api/geometry_msgs/html/msg/PointStamped.html">geometry_msgs/PointStamped</a>)</li>
</ul>
<h3><a class="anchor" id="autotoc_md146"></a>
Parameters</h3>
<ul>
<li><code>~clahe_clip</code> (double, default: 0.15, range: 0.0 - 40.0) Clip limit for CLAHE</li>
<li><code>~clahe_grid_size</code> (integer, default: 3, range: 1 - 16) Grid size of the CLAHE operator</li>
<li><code>~clahe_bilateral_iter</code> (integer, default: 2, range: 0 - 16) Number of iterations of bilateral filter after CLAHE is applied</li>
<li><code>~balanced_bilateral_iter</code> (integer, default: 2, range: 0 - 8) Number of iterations of bilateral filter after white balancing is applied</li>
<li><code>~denoise_h</code> (double, default: 10.0, range: 0.0 - 20.0) h value for fast non-local means denoising applied on the final blue-filtered image</li>
<li><code>~low_h</code> (int, default: 0, range: 0 - 255) Lower Bound of H</li>
<li><code>~high_h</code> (int, default: 10, range: 0 - 255) Higher Bound of H</li>
<li><code>~low_s</code> (int, default: 251, range: 0 - 255) Lower Bound of S</li>
<li><code>~high_s</code> (int, default: 255, range: 0 - 255) Higher Bound of S</li>
<li><code>~low_v</code> (int, default: 160, range: 0 - 255) Lower Bound of V</li>
<li><code>~high_v</code> (int, default: 255, range: 0 - 255) Higher Bound of V</li>
<li><code>~opening_mat_point</code> (int, default: 1, range: 1 - 7) Center of the matrix for the opening operation (size extrapolated 2x+1)</li>
<li><code>~opening_iter</code> (int, default: 0, range: 0 - 10) Iterations of opening applied on the thresholded image</li>
<li><code>~closing_mat_point</code> (int, default: 1, range: 1 - 7) Center of the matrix for the closing operation (size extrapolated 2x+1)</li>
<li><code>~closing_iter</code> (int, default: 0, range: 0 - 10) Iterations of closing applied on the opened thresholded image</li>
</ul>
<h2><a class="anchor" id="autotoc_md147"></a>
gate_task_bottom</h2>
<p>This task applies pre-processes (blue-filters) the raw image, applies thresholding on the image, draws a minimum enclosing rectangle on the main blob and publishes the coordinates of the gate's horizontal arm in the camera's reference frame and also publishes whether the task is done or not.</p>
<h3><a class="anchor" id="autotoc_md148"></a>
Published Topics</h3>
<ul>
<li>**<code>/gate_task/bottom/thresholded</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/gate_task/bottom/marked</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/gate_task/bottom/pipe_coordinates</code>** (<a href="http://docs.ros.org/kinetic/api/geometry_msgs/html/msg/PointStamped.html">geometry_msgs/PointStamped</a>)</li>
<li>**<code>/gate_task/done</code>** (<a href="http://docs.ros.org/kinetic/api/std_msgs/html/msg/Bool.html">std_msgs/Bool</a>)</li>
</ul>
<h3><a class="anchor" id="autotoc_md149"></a>
Parameters</h3>
<ul>
<li><code>~clahe_clip</code> (double, default: 4.0, range: 0.0 - 40.0) Clip limit for CLAHE</li>
<li><code>~clahe_grid_size</code> (integer, default: 8, range: 1 - 16) Grid size of the CLAHE operator</li>
<li><code>~clahe_bilateral_iter</code> (integer, default: 4, range: 0 - 16) Number of iterations of bilateral filter after CLAHE is applied</li>
<li><code>~balanced_bilateral_iter</code> (integer, default: 2, range: 0 - 8) Number of iterations of bilateral filter after white balancing is applied</li>
<li><code>~denoise_h</code> (double, default: 10.0, range: 0.0 - 20.0) h value for fast non-local means denoising applied on the final blue-filtered image</li>
<li><code>~low_h</code> (int, default: 0, range: 0 - 255) Lower Bound of H</li>
<li><code>~high_h</code> (int, default: 130, range: 0 - 255) Higher Bound of H</li>
<li><code>~low_s</code> (int, default: 0, range: 0 - 255) Lower Bound of S</li>
<li><code>~high_s</code> (int, default: 123, range: 0 - 255) Higher Bound of S</li>
<li><code>~low_v</code> (int, default: 95, range: 0 - 255) Lower Bound of V</li>
<li><code>~high_v</code> (int, default: 255, range: 0 - 255) Higher Bound of V</li>
<li><code>~closing_mat_point</code> (int, default: 2, range: 1 - 7) Center of the matrix for the closing operation (size extrapolated 2x+1)</li>
<li><code>~closing_iter</code> (int, default: 2, range: 0 - 10) Iterations of closing applied on the thresholded image</li>
</ul>
<h2><a class="anchor" id="autotoc_md150"></a>
gate_task_front</h2>
<p>This task applies pre-processes (blue-filters) the raw image, applies thresholding on the image, detects edges using Canny edge detection,detects straight lines using Probabilistic Hough <a class="el" href="classLine.html">Line</a> Transform, filters all the vertical and horizontal lines and detects which pair of these lines are perpendicular and close enough to be a gate. If multiple such pairs are found, the pair with longer lines is taken into considerations. This returns the coordinates of the gate in the camera's frame. The distance of the gate from the camera is calculated using an exponential mapping of the diagonal of the rectangle formed by the two arms and the actual distance. If both arms of the gate are not detected and only one of the arms is detected, the rectangle is extrapolated and the distance of the gate from the camera is also calculated based on this extrapolated rectangle.</p>
<h3><a class="anchor" id="autotoc_md151"></a>
Published Topics</h3>
<ul>
<li>**<code>/gate_task/front/blue_filtered</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/gate_task/front/thresholded</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/gate_task/front/canny</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/gate_task/front/lines</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/gate_task/front/marked</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/gate_task/front/gate_coordinates</code>** (<a href="http://docs.ros.org/kinetic/api/geometry_msgs/html/msg/PointStamped.html">geometry_msgs/PointStamped</a>)</li>
</ul>
<h3><a class="anchor" id="autotoc_md152"></a>
Parameters</h3>
<ul>
<li><code>~clahe_clip</code> (double, default: 0.15, range: 0.0 - 40.0) Clip limit for CLAHE</li>
<li><code>~clahe_grid_size</code> (integer, default: 3, range: 1 - 16) Grid size of the CLAHE operator</li>
<li><code>~clahe_bilateral_iter</code> (integer, default: 2, range: 0 - 16) Number of iterations of bilateral filter after CLAHE is applied</li>
<li><code>~balanced_bilateral_iter</code> (integer, default: 4, range: 0 - 8) Number of iterations of bilateral filter after white balancing is applied</li>
<li><code>~denoise_h</code> (double, default: 10.0, range: 0.0 - 20.0) h value for fast non-local means denoising applied on the final blue-filtered image</li>
<li><code>~low_h</code> (int, default: 0, range: 0 - 255) Lower Bound of H</li>
<li><code>~high_h</code> (int, default: 10, range: 0 - 255) Higher Bound of H</li>
<li><code>~low_s</code> (int, default: 156, range: 0 - 255) Lower Bound of S</li>
<li><code>~high_s</code> (int, default: 255, range: 0 - 255) Higher Bound of S</li>
<li><code>~low_v</code> (int, default: 88, range: 0 - 255) Lower Bound of V</li>
<li><code>~high_v</code> (int, default: 255, range: 0 - 255) Higher Bound of V</li>
<li><code>~closing_mat_point</code> (int, default: 1, range: 1 - 7) Center of the matrix for the closing operation (size extrapolated 2x+1)</li>
<li><code>~closing_iter</code> (int, default: 0, range: 0 - 10) Iterations of closing applied on the thresholded image</li>
<li><code>~canny_threshold_low</code> (int, default: 0, range: 0 - 1000) Lower threshold for the pixel intensity gradient</li>
<li><code>~canny_threshold_high</code> (int, default: 1000, range: 0 - 1000) Higher threshold for the pixel intensity gradient <br  />
</li>
<li><code>~canny_kernel_size</code> (int, default: 3, range: 3 - 7) Kernel size of the operator</li>
<li><code>~hough_minline</code> (int, default: 200, range: 0 - 500) Minimum length of the detected lines</li>
<li><code>~hough_threshold</code> (int, default: 105, range: 0 - 500) Minimum number of intersections to be considered as part of one line</li>
<li><code>~hough_maxgap</code> (int, default: 61, range: 0 - 500) Maximum gap between two points to be considered the same line</li>
<li><code>~hough_angle_tolerance</code> (double, default: 20.0, range: 0.0 - 45.0) Tolerance angle with respect to 0, 90 and 180 degrees to be considered as a probable line</li>
<li><code>~gate_distance_tolerance</code> (double, default: 50.0, range: 0.0 - 500.0) Maximum distance between atleast one pair of points to be considered close to each other</li>
<li><code>~gate_angle_tolerance</code> (double, default: 20.0, range: 0.0 - 45.0) Tolerance angle with respect to 90 to be considered as perpendicular</li>
</ul>
<h2><a class="anchor" id="autotoc_md153"></a>
line_task</h2>
<p>This task applies thresholding on the raw image, draws contours around the blob, finds straight lines using Probabilistic Hough <a class="el" href="classLine.html">Line</a> Transform and draws a tilted bounding rectangle around the contour. This returns the coordinates in the camera's reference frame using the bounding rectangle and returns the vehicle's angle with this line using the lines detected.</p>
<h3><a class="anchor" id="autotoc_md154"></a>
Published Topics</h3>
<ul>
<li>**<code>/line_task/thresholded</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/line_task/marked</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/line_task/gate_coordinates</code>** (<a href="http://docs.ros.org/api/geometry_msgs/html/msg/Pose2D.html">geometry_msgs/Pose2D</a>)</li>
</ul>
<h3><a class="anchor" id="autotoc_md155"></a>
Parameters</h3>
<ul>
<li><code>~low_h</code> (int, default: 31, range: 0 - 255) Lower Bound of H</li>
<li><code>~high_h</code> (int, default: 47, range: 0 - 255) Higher Bound of H</li>
<li><code>~low_s</code> (int, default: 0, range: 0 - 255) Lower Bound of S</li>
<li><code>~high_s</code> (int, default: 255, range: 0 - 255) Higher Bound of S</li>
<li><code>~low_v</code> (int, default: 0, range: 0 - 255) Lower Bound of V</li>
<li><code>~high_v</code> (int, default: 255, range: 0 - 255) Higher Bound of V</li>
<li><code>~opening_mat_point</code> (int, default: 1, range: 1 - 7) Center of the matrix for the opening operation (size extrapolated 2x+1)</li>
<li><code>~opening_iter</code> (int, default: 0, range: 0 - 10) Iterations of opening applied on the thresholded image</li>
<li><code>~closing_mat_point</code> (int, default: 2, range: 1 - 7) Center of the matrix for the closing operation (size extrapolated 2x+1)</li>
<li><code>~closing_iter</code> (int, default: 1, range: 0 - 10) Iterations of closing applied on the opened thresholded image</li>
</ul>
<h2><a class="anchor" id="autotoc_md156"></a>
torpedo_task</h2>
<p>This task applies pre-processes (blue-filters) the raw image, applies thresholding on the image, draws a minimum enclosing rectangle on all the detected contours. Based on the number of contours and their areas, an algorithm decides which of the contours is actually the heart and publishes the coordinates of the target in the camera's reference frame. The distance of the target from the camera is calculated using an exponential mapping of the width of the bounding rectangle and the actual distance.</p>
<h3><a class="anchor" id="autotoc_md157"></a>
Published Topics</h3>
<ul>
<li>**<code>/torpedo_task/thresholded</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/torpedo_task/marked</code>** (<a href="http://docs.ros.org/api/sensor_msgs/html/msg/Image.html">sensor_msgs/Image</a>)</li>
<li>**<code>/torpedo_task/gate_coordinates</code>** (<a href="http://docs.ros.org/api/geometry_msgs/html/msg/Pose2D.html">geometry_msgs/Pose2D</a>)</li>
</ul>
<h3><a class="anchor" id="autotoc_md158"></a>
Parameters</h3>
<ul>
<li><code>~clahe_clip</code> (double, default: 0.15, range: 0.0 - 40.0) Clip limit for CLAHE</li>
<li><code>~clahe_grid_size</code> (integer, default: 3, range: 1 - 16) Grid size of the CLAHE operator</li>
<li><code>~clahe_bilateral_iter</code> (integer, default: 2, range: 0 - 16) Number of iterations of bilateral filter after CLAHE is applied</li>
<li><code>~balanced_bilateral_iter</code> (integer, default: 4, range: 0 - 8) Number of iterations of bilateral filter after white balancing is applied</li>
<li><code>~denoise_h</code> (double, default: 5.6, range: 0.0 - 20.0) h value for fast non-local means denoising applied on the final blue-filtered image</li>
<li><code>~low_h</code> (int, default: 53, range: 0 - 255) Lower Bound of H</li>
<li><code>~high_h</code> (int, default: 86, range: 0 - 255) Higher Bound of H</li>
<li><code>~low_s</code> (int, default: 128, range: 0 - 255) Lower Bound of S</li>
<li><code>~high_s</code> (int, default: 255, range: 0 - 255) Higher Bound of S</li>
<li><code>~low_v</code> (int, default: 104, range: 0 - 255) Lower Bound of V</li>
<li><code>~high_v</code> (int, default: 202, range: 0 - 255) Higher Bound of V</li>
<li><code>~opening_mat_point</code> (int, default: 2, range: 1 - 7) Center of the matrix for the opening operation (size extrapolated 2x+1)</li>
<li><code>~opening_iter</code> (int, default: 1, range: 0 - 10) Iterations of opening applied on the thresholded image</li>
<li><code>~closing_mat_point</code> (int, default: 2, range: 1 - 7) Center of the matrix for the closing operation (size extrapolated 2x+1)</li>
<li><code>~closing_iter</code> (int, default: 3, range: 0 - 10) Iterations of closing applied on the opened thresholded image</li>
</ul>
<h1><a class="anchor" id="autotoc_md159"></a>
Bugs &amp; Feature Requests</h1>
<p>Please report bugs and request features using the <a href="https://github.com/AUV-IITK/auv2018/issues">Issue Tracker</a>. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.18
</small></address>
</body>
</html>
